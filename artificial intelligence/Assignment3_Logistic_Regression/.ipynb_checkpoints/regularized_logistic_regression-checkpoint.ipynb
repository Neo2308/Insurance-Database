{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "#### To classify News articles as belonging to two categories - business or sports (binary classification)\n",
    "\n",
    "Any editing needs to be done only in the cells marked with \"Tune hyperparameters here\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Useful notebook shortcuts:\n",
    "\n",
    "Ctrl+Enter -> Run current cell\n",
    "\n",
    "Shift+Enter -> Run current cell and go to next cell\n",
    "\n",
    "Alt+Enter -> Run current cell and add new cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from model import *\n",
    "from feature import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the training data directory\n",
    "sports = readfiles('train/sports')\n",
    "business = readfiles('train/business')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare bag-of-words based features (for the whole data)\n",
    "\n",
    "#### To run this block: \n",
    "\n",
    "Complete the `preprocess` and `extract` function in the `BagOfWordsFeatureExtractor` class in `feature.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and preprocess\n",
    "bow = BagOfWordsFeatureExtractor()\n",
    "bow.preprocess(business + sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fetures and create a numpy array of features\n",
    "X_business_bow = bow.extract(business)\n",
    "X_sports_bow = bow.extract(sports)\n",
    "X_data_bow = np.concatenate((X_business_bow, X_sports_bow))\n",
    "\n",
    "# We know the correct labels, so create a numpy array for correct labels\n",
    "# Business -> 0, Sports -> 1\n",
    "Y_data_bow = np.concatenate((np.zeros(X_business_bow.shape[0]), np.ones(X_sports_bow.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and val sets\n",
    "\n",
    "General convention is to have a train/val split in the ratio of 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_data_bow.shape[0]\n",
    "num_val = np.int(num_train*0.3)\n",
    "\n",
    "# Permute the indices to randomly split data into train and val\n",
    "data_idxs = np.random.permutation(num_train)\n",
    "\n",
    "# Separate train data\n",
    "X_train_bow = X_data_bow[data_idxs[num_val:], :]\n",
    "Y_train_bow = Y_data_bow[data_idxs[num_val:]]\n",
    "\n",
    "# Separate val data\n",
    "X_val_bow = X_data_bow[data_idxs[:num_val], :]\n",
    "Y_val_bow = Y_data_bow[data_idxs[:num_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters here\n",
    "The model will get trained and the loss at various iterations will be printed. Try and reduce this loss through hyperparameter tuning, to get a better validation set accuracy in the next block. However, don't chase the number to a 1.0, as the focus is on implementation rather than winning a contest.\n",
    "\n",
    "### To run this block: \n",
    "Complete the following functions in `model.py` of class `LogisticRegression`\n",
    "1. `loss`\n",
    "2. `train`\n",
    "3. `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of 10000. Loss: 5.624973\n",
      "Iteration 100 of 10000. Loss: 1.072846\n",
      "Iteration 200 of 10000. Loss: 0.712259\n",
      "Iteration 300 of 10000. Loss: 0.683695\n",
      "Iteration 400 of 10000. Loss: 0.681432\n",
      "Iteration 500 of 10000. Loss: 0.681252\n",
      "Iteration 600 of 10000. Loss: 0.681238\n",
      "Iteration 700 of 10000. Loss: 0.681237\n",
      "Iteration 800 of 10000. Loss: 0.681237\n",
      "Iteration 900 of 10000. Loss: 0.681237\n",
      "Iteration 1000 of 10000. Loss: 0.681237\n",
      "Iteration 1100 of 10000. Loss: 0.681237\n",
      "Iteration 1200 of 10000. Loss: 0.681237\n",
      "Iteration 1300 of 10000. Loss: 0.681237\n",
      "Iteration 1400 of 10000. Loss: 0.681237\n",
      "Iteration 1500 of 10000. Loss: 0.681237\n",
      "Iteration 1600 of 10000. Loss: 0.681237\n",
      "Iteration 1700 of 10000. Loss: 0.681237\n",
      "Iteration 1800 of 10000. Loss: 0.681237\n",
      "Iteration 1900 of 10000. Loss: 0.681237\n",
      "Iteration 2000 of 10000. Loss: 0.681237\n",
      "Iteration 2100 of 10000. Loss: 0.681237\n",
      "Iteration 2200 of 10000. Loss: 0.681237\n",
      "Iteration 2300 of 10000. Loss: 0.681237\n",
      "Iteration 2400 of 10000. Loss: 0.681237\n",
      "Iteration 2500 of 10000. Loss: 0.681237\n",
      "Iteration 2600 of 10000. Loss: 0.681237\n",
      "Iteration 2700 of 10000. Loss: 0.681237\n",
      "Iteration 2800 of 10000. Loss: 0.681237\n",
      "Iteration 2900 of 10000. Loss: 0.681237\n",
      "Iteration 3000 of 10000. Loss: 0.681237\n",
      "Iteration 3100 of 10000. Loss: 0.681237\n",
      "Iteration 3200 of 10000. Loss: 0.681237\n",
      "Iteration 3300 of 10000. Loss: 0.681237\n",
      "Iteration 3400 of 10000. Loss: 0.681237\n",
      "Iteration 3500 of 10000. Loss: 0.681237\n",
      "Iteration 3600 of 10000. Loss: 0.681237\n",
      "Iteration 3700 of 10000. Loss: 0.681237\n",
      "Iteration 3800 of 10000. Loss: 0.681237\n",
      "Iteration 3900 of 10000. Loss: 0.681237\n",
      "Iteration 4000 of 10000. Loss: 0.681237\n",
      "Iteration 4100 of 10000. Loss: 0.681237\n",
      "Iteration 4200 of 10000. Loss: 0.681237\n",
      "Iteration 4300 of 10000. Loss: 0.681237\n",
      "Iteration 4400 of 10000. Loss: 0.681237\n",
      "Iteration 4500 of 10000. Loss: 0.681237\n",
      "Iteration 4600 of 10000. Loss: 0.681237\n",
      "Iteration 4700 of 10000. Loss: 0.681237\n",
      "Iteration 4800 of 10000. Loss: 0.681237\n",
      "Iteration 4900 of 10000. Loss: 0.681237\n",
      "Iteration 5000 of 10000. Loss: 0.681237\n",
      "Iteration 5100 of 10000. Loss: 0.681237\n",
      "Iteration 5200 of 10000. Loss: 0.681237\n",
      "Iteration 5300 of 10000. Loss: 0.681237\n",
      "Iteration 5400 of 10000. Loss: 0.681237\n",
      "Iteration 5500 of 10000. Loss: 0.681237\n",
      "Iteration 5600 of 10000. Loss: 0.681237\n",
      "Iteration 5700 of 10000. Loss: 0.681237\n",
      "Iteration 5800 of 10000. Loss: 0.681237\n",
      "Iteration 5900 of 10000. Loss: 0.681237\n",
      "Iteration 6000 of 10000. Loss: 0.681237\n",
      "Iteration 6100 of 10000. Loss: 0.681237\n",
      "Iteration 6200 of 10000. Loss: 0.681237\n",
      "Iteration 6300 of 10000. Loss: 0.681237\n",
      "Iteration 6400 of 10000. Loss: 0.681237\n",
      "Iteration 6500 of 10000. Loss: 0.681237\n",
      "Iteration 6600 of 10000. Loss: 0.681237\n",
      "Iteration 6700 of 10000. Loss: 0.681237\n",
      "Iteration 6800 of 10000. Loss: 0.681237\n",
      "Iteration 6900 of 10000. Loss: 0.681237\n",
      "Iteration 7000 of 10000. Loss: 0.681237\n",
      "Iteration 7100 of 10000. Loss: 0.681237\n",
      "Iteration 7200 of 10000. Loss: 0.681237\n",
      "Iteration 7300 of 10000. Loss: 0.681237\n",
      "Iteration 7400 of 10000. Loss: 0.681237\n",
      "Iteration 7500 of 10000. Loss: 0.681237\n",
      "Iteration 7600 of 10000. Loss: 0.681237\n",
      "Iteration 7700 of 10000. Loss: 0.681237\n",
      "Iteration 7800 of 10000. Loss: 0.681237\n",
      "Iteration 7900 of 10000. Loss: 0.681237\n",
      "Iteration 8000 of 10000. Loss: 0.681237\n",
      "Iteration 8100 of 10000. Loss: 0.681237\n",
      "Iteration 8200 of 10000. Loss: 0.681237\n",
      "Iteration 8300 of 10000. Loss: 0.681237\n",
      "Iteration 8400 of 10000. Loss: 0.681237\n",
      "Iteration 8500 of 10000. Loss: 0.681237\n",
      "Iteration 8600 of 10000. Loss: 0.681237\n",
      "Iteration 8700 of 10000. Loss: 0.681237\n",
      "Iteration 8800 of 10000. Loss: 0.681237\n",
      "Iteration 8900 of 10000. Loss: 0.681237\n",
      "Iteration 9000 of 10000. Loss: 0.681237\n",
      "Iteration 9100 of 10000. Loss: 0.681237\n",
      "Iteration 9200 of 10000. Loss: 0.681237\n",
      "Iteration 9300 of 10000. Loss: 0.681237\n",
      "Iteration 9400 of 10000. Loss: 0.681237\n",
      "Iteration 9500 of 10000. Loss: 0.681237\n",
      "Iteration 9600 of 10000. Loss: 0.681237\n",
      "Iteration 9700 of 10000. Loss: 0.681237\n",
      "Iteration 9800 of 10000. Loss: 0.681237\n",
      "Iteration 9900 of 10000. Loss: 0.681237\n"
     ]
    }
   ],
   "source": [
    "lr = 9.5           # Try changing the learning rate\n",
    "reg_const = 10        # Try changing the regularization constant\n",
    "add_bias = False        # Does adding bias help? Try changing between True and False\n",
    "num_iter = 10000        # Do not change\n",
    "\n",
    "model1 = LogisticRegression(add_bias) \n",
    "model1.train(X_train_bow, Y_train_bow, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Accuracy using Bag-of-words features\n",
    "\n",
    "We use the function `score` of class `LogisticRegression` in the file `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Set Accuracy -  0.9844444444444445\n"
     ]
    }
   ],
   "source": [
    "val_acc = model1.score(X_val_bow, Y_val_bow)\n",
    "print(\"Final Validation Set Accuracy - \", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for above model get recorded\n",
    "\n",
    "These hyperparameters will be your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hyper('bow', add_bias, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tf-Idf based features (for the whole data)\n",
    "\n",
    "#### To run this block: \n",
    "Complete the `preprocess` and `extract` functions in the `TfIdfFeatureExtractor` class in `feature.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and preprocess\n",
    "tfidf = TfIdfFeatureExtractor()\n",
    "tfidf.preprocess(business + sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fetures and create a numpy array of features\n",
    "X_business_tfidf = tfidf.extract(business)\n",
    "X_sports_tfidf = tfidf.extract(sports)\n",
    "X_data_tfidf = np.concatenate((X_business_tfidf, X_sports_tfidf))\n",
    "\n",
    "# We know the correct labels, so create a numpy array for correct labels\n",
    "# Business -> 0, Sports -> 1\n",
    "Y_data_tfidf = np.concatenate((np.zeros(X_business_tfidf.shape[0]), np.ones(X_sports_tfidf.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and val sets\n",
    "\n",
    "General convention is to have a train/val split in the ratio of 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_business_tfidf.shape[0] + X_sports_tfidf.shape[0]\n",
    "num_val = np.int(num_train*0.3)\n",
    "X_data_tfidf = np.concatenate((X_business_tfidf, X_sports_tfidf))\n",
    "Y_data_tfidf = np.concatenate((np.zeros(X_business_tfidf.shape[0]), np.ones(X_sports_tfidf.shape[0])))\n",
    "\n",
    "# Data_idxs have been used from Bag of words section, so that we can fairly compare accuracies\n",
    "\n",
    "# Separate train data\n",
    "X_train_tfidf = X_data_tfidf[data_idxs[num_val:], :]\n",
    "Y_train_tfidf = Y_data_tfidf[data_idxs[num_val:]]\n",
    "\n",
    "# Separate val data\n",
    "X_val_tfidf = X_data_tfidf[data_idxs[:num_val], :]\n",
    "Y_val_tfidf = Y_data_tfidf[data_idxs[:num_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters here\n",
    "The model will get trained and the loss at various iterations will be printed. Try and reduce this loss through hyperparameter tuning, to get a better validation set accuracy in the next block. However, don't chase the number to a 1.0, as the focus is on implementation rather than winning a contest.\n",
    "\n",
    "You should have already implemented all the necessary functions to run this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of 10000. Loss: 5.644533\n",
      "Iteration 100 of 10000. Loss: 1.035931\n",
      "Iteration 200 of 10000. Loss: 0.673072\n",
      "Iteration 300 of 10000. Loss: 0.644471\n",
      "Iteration 400 of 10000. Loss: 0.642215\n",
      "Iteration 500 of 10000. Loss: 0.642037\n",
      "Iteration 600 of 10000. Loss: 0.642023\n",
      "Iteration 700 of 10000. Loss: 0.642022\n",
      "Iteration 800 of 10000. Loss: 0.642022\n",
      "Iteration 900 of 10000. Loss: 0.642022\n",
      "Iteration 1000 of 10000. Loss: 0.642022\n",
      "Iteration 1100 of 10000. Loss: 0.642022\n",
      "Iteration 1200 of 10000. Loss: 0.642022\n",
      "Iteration 1300 of 10000. Loss: 0.642022\n",
      "Iteration 1400 of 10000. Loss: 0.642022\n",
      "Iteration 1500 of 10000. Loss: 0.642022\n",
      "Iteration 1600 of 10000. Loss: 0.642022\n",
      "Iteration 1700 of 10000. Loss: 0.642022\n",
      "Iteration 1800 of 10000. Loss: 0.642022\n",
      "Iteration 1900 of 10000. Loss: 0.642022\n",
      "Iteration 2000 of 10000. Loss: 0.642022\n",
      "Iteration 2100 of 10000. Loss: 0.642022\n",
      "Iteration 2200 of 10000. Loss: 0.642022\n",
      "Iteration 2300 of 10000. Loss: 0.642022\n",
      "Iteration 2400 of 10000. Loss: 0.642022\n",
      "Iteration 2500 of 10000. Loss: 0.642022\n",
      "Iteration 2600 of 10000. Loss: 0.642022\n",
      "Iteration 2700 of 10000. Loss: 0.642022\n",
      "Iteration 2800 of 10000. Loss: 0.642022\n",
      "Iteration 2900 of 10000. Loss: 0.642022\n",
      "Iteration 3000 of 10000. Loss: 0.642022\n",
      "Iteration 3100 of 10000. Loss: 0.642022\n",
      "Iteration 3200 of 10000. Loss: 0.642022\n",
      "Iteration 3300 of 10000. Loss: 0.642022\n",
      "Iteration 3400 of 10000. Loss: 0.642022\n",
      "Iteration 3500 of 10000. Loss: 0.642022\n",
      "Iteration 3600 of 10000. Loss: 0.642022\n",
      "Iteration 3700 of 10000. Loss: 0.642022\n",
      "Iteration 3800 of 10000. Loss: 0.642022\n",
      "Iteration 3900 of 10000. Loss: 0.642022\n",
      "Iteration 4000 of 10000. Loss: 0.642022\n",
      "Iteration 4100 of 10000. Loss: 0.642022\n",
      "Iteration 4200 of 10000. Loss: 0.642022\n",
      "Iteration 4300 of 10000. Loss: 0.642022\n",
      "Iteration 4400 of 10000. Loss: 0.642022\n",
      "Iteration 4500 of 10000. Loss: 0.642022\n",
      "Iteration 4600 of 10000. Loss: 0.642022\n",
      "Iteration 4700 of 10000. Loss: 0.642022\n",
      "Iteration 4800 of 10000. Loss: 0.642022\n",
      "Iteration 4900 of 10000. Loss: 0.642022\n",
      "Iteration 5000 of 10000. Loss: 0.642022\n",
      "Iteration 5100 of 10000. Loss: 0.642022\n",
      "Iteration 5200 of 10000. Loss: 0.642022\n",
      "Iteration 5300 of 10000. Loss: 0.642022\n",
      "Iteration 5400 of 10000. Loss: 0.642022\n",
      "Iteration 5500 of 10000. Loss: 0.642022\n",
      "Iteration 5600 of 10000. Loss: 0.642022\n",
      "Iteration 5700 of 10000. Loss: 0.642022\n",
      "Iteration 5800 of 10000. Loss: 0.642022\n",
      "Iteration 5900 of 10000. Loss: 0.642022\n",
      "Iteration 6000 of 10000. Loss: 0.642022\n",
      "Iteration 6100 of 10000. Loss: 0.642022\n",
      "Iteration 6200 of 10000. Loss: 0.642022\n",
      "Iteration 6300 of 10000. Loss: 0.642022\n",
      "Iteration 6400 of 10000. Loss: 0.642022\n",
      "Iteration 6500 of 10000. Loss: 0.642022\n",
      "Iteration 6600 of 10000. Loss: 0.642022\n",
      "Iteration 6700 of 10000. Loss: 0.642022\n",
      "Iteration 6800 of 10000. Loss: 0.642022\n",
      "Iteration 6900 of 10000. Loss: 0.642022\n",
      "Iteration 7000 of 10000. Loss: 0.642022\n",
      "Iteration 7100 of 10000. Loss: 0.642022\n",
      "Iteration 7200 of 10000. Loss: 0.642022\n",
      "Iteration 7300 of 10000. Loss: 0.642022\n",
      "Iteration 7400 of 10000. Loss: 0.642022\n",
      "Iteration 7500 of 10000. Loss: 0.642022\n",
      "Iteration 7600 of 10000. Loss: 0.642022\n",
      "Iteration 7700 of 10000. Loss: 0.642022\n",
      "Iteration 7800 of 10000. Loss: 0.642022\n",
      "Iteration 7900 of 10000. Loss: 0.642022\n",
      "Iteration 8000 of 10000. Loss: 0.642022\n",
      "Iteration 8100 of 10000. Loss: 0.642022\n",
      "Iteration 8200 of 10000. Loss: 0.642022\n",
      "Iteration 8300 of 10000. Loss: 0.642022\n",
      "Iteration 8400 of 10000. Loss: 0.642022\n",
      "Iteration 8500 of 10000. Loss: 0.642022\n",
      "Iteration 8600 of 10000. Loss: 0.642022\n",
      "Iteration 8700 of 10000. Loss: 0.642022\n",
      "Iteration 8800 of 10000. Loss: 0.642022\n",
      "Iteration 8900 of 10000. Loss: 0.642022\n",
      "Iteration 9000 of 10000. Loss: 0.642022\n",
      "Iteration 9100 of 10000. Loss: 0.642022\n",
      "Iteration 9200 of 10000. Loss: 0.642022\n",
      "Iteration 9300 of 10000. Loss: 0.642022\n",
      "Iteration 9400 of 10000. Loss: 0.642022\n",
      "Iteration 9500 of 10000. Loss: 0.642022\n",
      "Iteration 9600 of 10000. Loss: 0.642022\n",
      "Iteration 9700 of 10000. Loss: 0.642022\n",
      "Iteration 9800 of 10000. Loss: 0.642022\n",
      "Iteration 9900 of 10000. Loss: 0.642022\n"
     ]
    }
   ],
   "source": [
    "lr = 9.5              # Try changing the learning rate\n",
    "reg_const = 10         # Try changing the regularization constant\n",
    "add_bias = False        # Does adding bias help? Try changing between True and False\n",
    "num_iter = 10000        # Do not change\n",
    "\n",
    "model2 = LogisticRegression(add_bias)\n",
    "model2.train(X_train_tfidf, Y_train_tfidf, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Accuracy using Bag-of-words features\n",
    "\n",
    "We use the function `score` of class `LogisticRegression` in the file `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Set Accuracy -  0.9955555555555555\n"
     ]
    }
   ],
   "source": [
    "val_acc = model2.score(X_val_tfidf, Y_val_tfidf)\n",
    "print(\"Final Validation Set Accuracy - \", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for above model get recorded\n",
    "\n",
    "These hyperparameters will be your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hyper('tf-idf', add_bias, lr, reg_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
